Parameters:

TRAIN_DATA = ./data/wikitext-103/wiki.train.tokens
VAL_DATA = ./data/wikitext-103/wiki.valid.tokens
TEST_DATA = ./data/wikitext-103/wiki.test.tokens
DEFS_TRAIN_DATA = ./data/main_data/definitions_train.json
DEFS_VAL_DATA = ./data/main_data/definitions_val.json
DEFS_TEST_DATA = ./data/main_data/definitions_test.json
INIT_WV = True
WV_WEIGHTS = ./data/w2v_embeddings/GoogleNews-vectors-negative300.bin
SEED = 42
CUDA = True
BATCH_SIZE = 32
SEQLEN = 30
NCOND = 300
NX = 300
NHID = 300
NUM_EPOCHS = 1
NLAYERS = 3
DROPOUT_PROB = 0.5
INITIAL_LR = 0.001
DECAY_FACTOR = 0.1
DECAY PATIENCE = 0
GRAD_CLIP = 5
MODEL_CKPT = ./pretrain_wiki_exp/best_pretrain
TRAIN = True
SAVE_VOCAB_TO = ./pretrain_wiki_exp/wiki_vocab.json


RESULTS:

TRAIN PPL: 252.20173177513712
VAL PPL: 139.31071161641495
TEST PPL: 141.92742472186077
