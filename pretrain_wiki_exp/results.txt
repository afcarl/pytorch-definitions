Parameters:

TRAIN_DATA = ./data/wikitext-103/wiki.train.tokens
VAL_DATA = ./data/wikitext-103/wiki.valid.tokens
TEST_DATA = ./data/wikitext-103/wiki.test.tokens
INIT_WV = True
WV_WEIGHTS = ./data/w2v_embeddings/GoogleNews-vectors-negative300.bin
SEED = 42
CUDA = True
BATCH_SIZE = 32
SEQLEN = 30
NCOND = 300
NX = 300
NHID = 300
NUM_EPOCHS = 1
NLAYERS = 3
DROPOUT_PROB = 0.5
INITIAL_LR = 0.001
DECAY_FACTOR = 0.1
DECAY PATIENCE = 0
GRAD_CLIP = 5
MODEL_CKPT = ./pretrain_wiki_exp/best_pretrain
TRAIN = True
SAVE_VOCAB_TO = ./pretrain_wiki_exp/wiki_vocab.json


RESULTS:

TRAIN PPL: 268.8654622044516
VAL PPL: 145.44297079613918
TEST PPL: 148.34657472696728
